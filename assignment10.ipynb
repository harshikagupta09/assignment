{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1 Importing the packages\n",
    "import sklearn as preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing package for datasets\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit = load_digits()\n",
    "x = digit.data\n",
    "y = digit.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797L, 64L), (1797L,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape , y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xe545dd8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe6b8b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Question 2\n",
    "plt.imshow(x[5].reshape(8,8),cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 3\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 4\n",
    "reg = LogisticRegression()\n",
    "reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 5(a)classification accuracy means no. of cross predictions made as a ratio of all predictions made.\n",
    "pred = reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual  Predicted\n",
       "0         9          5\n",
       "1         9          9\n",
       "2         9          9\n",
       "3         1          1\n",
       "4         2          2\n",
       "5         8          8\n",
       "6         5          5\n",
       "7         1          1\n",
       "8         0          0\n",
       "9         6          6\n",
       "10        2          2\n",
       "11        6          6\n",
       "12        7          7\n",
       "13        3          3\n",
       "14        3          3\n",
       "15        9          9\n",
       "16        8          8\n",
       "17        3          3\n",
       "18        4          7\n",
       "19        3          3\n",
       "20        0          0\n",
       "21        1          1\n",
       "22        3          3\n",
       "23        4          4\n",
       "24        5          5\n",
       "25        5          5\n",
       "26        1          1\n",
       "27        2          2\n",
       "28        2          2\n",
       "29        1          8\n",
       "..      ...        ...\n",
       "510       1          1\n",
       "511       8          8\n",
       "512       9          9\n",
       "513       5          5\n",
       "514       8          8\n",
       "515       4          4\n",
       "516       2          2\n",
       "517       5          5\n",
       "518       7          7\n",
       "519       7          7\n",
       "520       4          4\n",
       "521       8          8\n",
       "522       2          2\n",
       "523       0          0\n",
       "524       2          2\n",
       "525       7          7\n",
       "526       0          0\n",
       "527       8          8\n",
       "528       7          7\n",
       "529       0          0\n",
       "530       3          3\n",
       "531       5          5\n",
       "532       8          8\n",
       "533       2          2\n",
       "534       0          0\n",
       "535       4          4\n",
       "536       0          0\n",
       "537       1          1\n",
       "538       0          0\n",
       "539       7          7\n",
       "\n",
       "[540 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\"Predicted\":pred,\"Actual\":y_test})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = model_selection.KFold(n_splits=10,random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90555556, 0.95      , 0.89444444, 0.91666667, 0.94444444,\n",
       "       0.97222222, 0.97777778, 0.95530726, 0.8603352 , 0.93854749])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model_selection.cross_val_score(reg,x,y,cv=kfold,scoring=\"accuracy\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.931530105524519"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sum()/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.45778991, -0.14434019, -0.61739005, -0.27333073, -0.27594791,\n",
       "       -0.12824496, -0.11027347, -0.12335714, -0.62604368, -0.6855272 ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 5(b)Logarithmic loss means performance metrics for evaluating the predictions of probabilities of membership to a given class. \n",
    "results = model_selection.cross_val_score(reg,x,y,cv=kfold,scoring=\"neg_log_loss\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.34422452331430986"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sum()/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[55,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 54,  1,  0,  0,  1,  0,  0,  1,  0],\n",
       "       [ 0,  0, 44,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 43,  0,  0,  0,  0,  4,  0],\n",
       "       [ 0,  2,  0,  0, 52,  0,  1,  1,  0,  0],\n",
       "       [ 0,  2,  0,  0,  0, 46,  2,  1,  0,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0, 58,  0,  0,  0],\n",
       "       [ 0,  1,  0,  0,  1,  0,  0, 52,  1,  1],\n",
       "       [ 0,  1,  0,  1,  0,  0,  0,  0, 55,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1,  0,  1,  2, 53]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 5(f)confusion_matrix means presentation of the accuracy of a model with two or more classes.\n",
    "confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        55\n",
      "          1       0.90      0.95      0.92        57\n",
      "          2       0.98      1.00      0.99        44\n",
      "          3       0.98      0.91      0.95        47\n",
      "          4       0.98      0.93      0.95        56\n",
      "          5       0.96      0.87      0.91        53\n",
      "          6       0.95      1.00      0.97        58\n",
      "          7       0.95      0.93      0.94        56\n",
      "          8       0.87      0.96      0.92        57\n",
      "          9       0.95      0.93      0.94        57\n",
      "\n",
      "avg / total       0.95      0.95      0.95       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Question 5(g) classification_report means its a function display the precision, recall, f1-score and support for each class.\n",
    "print (classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73184699, 0.86942354, 0.81023661, 0.79423609, 0.82434177,\n",
       "       0.94343263, 0.92524112, 0.90725247, 0.60169024, 0.82555495])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 5(c)R2 metrics provides an indication of the goodness of fit of a set of predictions to the actual values.\n",
    "#R2 metrics measures the coefficient of determination.\n",
    "reg1 = LinearRegression()\n",
    "results = model_selection.cross_val_score(reg,x,y,cv=kfold,scoring=\"r2\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8233256404108781"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sum()/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.76232318, -1.33110792, -1.55360439, -1.51943658, -1.50040068,\n",
       "       -1.30773649, -1.41940728, -1.60049753, -1.62693098, -1.75390435])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 5(d)Mean absolute error means the sum of the absolute differences between predictions and actual values.\n",
    "results = model_selection.cross_val_score(reg1,x,y,cv=kfold,scoring=\"neg_mean_absolute_error\")\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.5375349366952842"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sum()/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.08763116, -2.93563178, -3.5440648 , -3.35720712, -3.61041109,\n",
       "       -2.77252253, -3.06878144, -4.29164324, -4.76128221, -4.75789407])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 5(e)Mean squared error means provides a gross idea of the magnitude of error.\n",
    "results = model_selection.cross_val_score(reg1,x,y,cv=kfold,scoring=\"neg_mean_squared_error\")\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.81870694491852"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sum()/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
